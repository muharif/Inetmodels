{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib, os, shutil\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from tqdm import tqdm_notebook\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "import gseapy as gp\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import pyranges as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc(df):\n",
    "#     print('Calculating Correlation..')\n",
    "#     temp=spearmanr(df.T)\n",
    "#     corr=pd.DataFrame(temp[0],columns=list(df.index),index=list(df.index))\n",
    "#     pval=pd.DataFrame(temp[1],columns=list(df.index),index=list(df.index))\n",
    "#     print('Filtering the matrix Correlation..')\n",
    "#     corr=corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\n",
    "#     pval=pval.where(np.triu(np.ones(pval.shape)).astype(np.bool))\n",
    "#     print('Making long table of Correlation..')\n",
    "#     corr2=corr.unstack().reset_index(name='weight')\n",
    "#     pval2=pval.unstack().reset_index(name='pval')\n",
    "#     res=corr2.merge(pval2,on=['level_0','level_1'])\n",
    "#     res=res[res['level_0'] != res['level_1']]\n",
    "#     res=res.dropna()\n",
    "#     res=res[['level_0','level_1','weight','pval']]\n",
    "#     res['padj']=multipletests(res['pval'],method='fdr_bh')[1]\n",
    "#     res=res[res.padj < 0.05].reset_index(drop=True)\n",
    "#     print('Done!!')\n",
    "#     return res\n",
    "\n",
    "class Network_Analysis:\n",
    "    def __init__(self,raw_data,nodes,respath,cat):\n",
    "        self.res_path=respath\n",
    "        self.cat=cat\n",
    "        if os.path.isdir(self.res_path):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(self.res_path)\n",
    "        self.network_ori=self.__calc(raw_data)\n",
    "        self.nodes=nodes\n",
    "\n",
    "        print('Network Analysis')\n",
    "        self.__net_analysis_combi()\n",
    "    \n",
    "    def __calc(self,df):\n",
    "        print('Calculating Correlation..')\n",
    "        temp=spearmanr(df.T)\n",
    "        corr=pd.DataFrame(temp[0],columns=list(df.index),index=list(df.index))\n",
    "        pval=pd.DataFrame(temp[1],columns=list(df.index),index=list(df.index))\n",
    "        print('Filtering the matrix Correlation..')\n",
    "        corr=corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\n",
    "        pval=pval.where(np.triu(np.ones(pval.shape)).astype(np.bool))\n",
    "        print('Making long table of Correlation..')\n",
    "        corr2=corr.unstack().reset_index(name='weight')\n",
    "        pval2=pval.unstack().reset_index(name='pval')\n",
    "        res=corr2.merge(pval2,on=['level_0','level_1'])\n",
    "        res=res[res['level_0'] != res['level_1']]\n",
    "        res=res.dropna()\n",
    "        res=res[['level_0','level_1','weight','pval']]\n",
    "        res['category'] = self.cat\n",
    "        res['padj']=multipletests(res['pval'],method='fdr_bh')[1]\n",
    "        res=res[res.padj < 0.05].reset_index(drop=True)\n",
    "        res.columns=['source','target','correlation','pvalue','category','padj']\n",
    "        res=res[['source','target','category','correlation','pvalue','padj']]\n",
    "        res.to_csv('%s/%d_edges.txt' % (self.res_path,self.cat),sep='\\t',index=False)\n",
    "        print('Done!!')\n",
    "        return res\n",
    "    \n",
    "    def __net_analysis_combi(self):\n",
    "        print('Loading The Network...')\n",
    "        temp=self.network_ori\n",
    "        g= ig.Graph.TupleList(zip(temp['source'],temp['target'],temp['correlation']),weights=True)\n",
    "        G_pos = g.subgraph_edges(g.es.select(weight_gt = 0), delete_vertices=False)\n",
    "        G_neg = g.subgraph_edges(g.es.select(weight_lt = 0), delete_vertices=False)\n",
    "        G_neg.es['weight'] = [-w for w in G_neg.es['weight']]\n",
    "        part_pos = leidenalg.ModularityVertexPartition(G_pos, weights='weight')\n",
    "        part_neg = leidenalg.ModularityVertexPartition(G_neg, weights='weight');\n",
    "        optimiser = leidenalg.Optimiser()\n",
    "        diff = optimiser.optimise_partition_multiplex([part_pos, part_neg],layer_weights=[1,-1], n_iterations=-1)\n",
    "        self.clustering_combi=pd.DataFrame(pd.Series(part_pos.membership+part_neg.membership,index=G_pos.vs['name']+G_neg.vs['name'])).reset_index().drop_duplicates().set_index('index')[0]\n",
    "        print('Cluster Analysis...')\n",
    "        self.modularity_combi=diff\n",
    "        open('%s/%d_modularity.txt' % (self.res_path,self.cat),'w').write(str(diff))\n",
    "        self.nodes['cluster'] = self.clustering_combi.reindex(self.nodes.index).tolist()\n",
    "        self.nodes.to_csv('%s/%d_nodes.txt' % (self.res_path,self.cat),sep='\\t')\n",
    "    \n",
    "    def save_network(self):\n",
    "        pickle_out = open('%s/%d_network_object.pkl' % (self.res_path,self.cat),\"wb\")\n",
    "        pickle.dump(self, pickle_out)\n",
    "        pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta=pd.read_csv('../Data/GTEX/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt',sep='\\t',index_col=0)[['SMTSD']]\n",
    "# meta2=pd.read_csv('../Data/GTEX/GTEx_Analysis_v8_Annotations_SubjectPhenotypesDS.txt',sep='\\t',index_col=0)[['SEX','AGE']]\n",
    "# new_meta=[]\n",
    "# for i in meta.index:\n",
    "#     temp='-'.join(i.split('-')[0:2])\n",
    "#     new_meta.append([meta2.loc[temp]['SEX'],meta2.loc[temp]['AGE']])\n",
    "# new_meta=pd.DataFrame(new_meta,index=meta.index,columns=['SEX','AGE'])\n",
    "# meta=pd.concat([meta,new_meta],1)\n",
    "# data=pd.read_csv('../Data/GTEX/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz', sep='\\t',skiprows=2,nrows=2,index_col=0)\n",
    "# # meta=pd.read_csv('../Data/GTEX/metadata_final.txt',sep='\\t',index_col=0)\n",
    "# meta.reindex(data.columns[1:]).to_csv('../Data/GTEX/metadata_final.txt',sep='\\t')\n",
    "\n",
    "# pc=pr.read_gtf('../Data/GTEX/gencode.v26.GRCh38.genes.gtf').df\n",
    "# pc=pc[pc['gene_type'] == 'protein_coding'][['gene_id','gene_name']].drop_duplicates()\n",
    "# pc['ensembl']=[i.split('.')[0] for i in pc['gene_id']]\n",
    "# protein_atlas=pd.read_csv('../../MainLibrary/proteinatlas.tsv',sep='\\t',index_col='Ensembl')[['Gene','Gene synonym','Uniprot']]\n",
    "# pc=pc.merge(protein_atlas,right_on='Ensembl',left_on='ensembl')\n",
    "# pc.set_index('gene_id').to_csv('../Data/GTEX/protein_coding.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=pd.read_csv('../Data/GTEX/metadata_final.txt',sep='\\t',index_col=0)\n",
    "pc=pd.read_csv('../Data/GTEX/protein_coding.txt',sep='\\t',index_col=0)\n",
    "cat=pd.DataFrame(meta['SMTSD'].unique(),columns=['name_category']).reset_index()\n",
    "cat.columns=['id_category','name_category']\n",
    "cat['type_category'] = 'Normal Tissue'\n",
    "cat=cat.set_index('id_category')\n",
    "cat.to_csv('../Results/GTEx/category.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat.index[0:2]:\n",
    "    temp=['Name']+list(meta[meta['SMTSD'] == cat.loc[i]['name_category']].index)\n",
    "    tpm=pd.read_csv('../Data/GTEX/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz', sep='\\t',skiprows=2,index_col=0,usecols=temp).reindex(set(pc.index)).dropna(how='all')\n",
    "    tpm=tpm[tpm.mean(1)>1]\n",
    "    nodes=pc[['Gene','ensembl']].reindex(tpm.index)\n",
    "    nodes.columns=['symbol','info1']\n",
    "    mean=tpm.mean(1)\n",
    "    sd=tpm.std(1)\n",
    "    mins=tpm.min(1)\n",
    "    maxs=tpm.max(1)\n",
    "    ran=['%.1f - %.1f' % (mins.loc[k],maxs.loc[k]) for k in mins.index]\n",
    "    mean=['%.1f (+/- %.1f)' % (mean.loc[k],sd.loc[k]) for k in mins.index]\n",
    "    nodes['info2'] = mean\n",
    "    nodes['info3'] =ran\n",
    "    nodes['location'] = 'GENE'\n",
    "    nodes['category'] = i\n",
    "    print('StartingNet')\n",
    "    k=Network_Analysis(raw_data=tpm,nodes=nodes,respath='../Results/GTEx/',cat=i)\n",
    "    print('SavingNet')\n",
    "    k.save_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, leidenalg, pickle\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import igraph as ig\n",
    "\n",
    "class Network_Analysis:\n",
    "    def __init__(self,raw_data,nodes,respath,cat):\n",
    "        self.res_path=respath\n",
    "        self.cat=cat\n",
    "        if os.path.isdir(self.res_path):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(self.res_path)\n",
    "        self.network_ori=self.__calc(raw_data)\n",
    "        self.nodes=nodes\n",
    "\n",
    "        print('Network Analysis')\n",
    "        self.__net_analysis_combi()\n",
    "    \n",
    "    def __calc(self,df):\n",
    "        print('Calculating Correlation..')\n",
    "        temp=spearmanr(df.T)\n",
    "        corr=pd.DataFrame(temp[0],columns=list(df.index),index=list(df.index))\n",
    "        pval=pd.DataFrame(temp[1],columns=list(df.index),index=list(df.index))\n",
    "        print('Filtering the matrix Correlation..')\n",
    "        corr=corr.where(np.triu(np.ones(corr.shape)).astype(np.bool))\n",
    "        pval=pval.where(np.triu(np.ones(pval.shape)).astype(np.bool))\n",
    "        print('Making long table of Correlation..')\n",
    "        corr2=corr.unstack().reset_index(name='weight')\n",
    "        pval2=pval.unstack().reset_index(name='pval')\n",
    "        res=corr2.merge(pval2,on=['level_0','level_1'])\n",
    "        res=res[res['level_0'] != res['level_1']]\n",
    "        res=res.dropna()\n",
    "        res=res[['level_0','level_1','weight','pval']]\n",
    "        res['category'] = self.cat\n",
    "        res['padj']=multipletests(res['pval'],method='fdr_bh')[1]\n",
    "        res=res[res.padj < 0.05].reset_index(drop=True)\n",
    "        res.columns=['source','target','correlation','pvalue','category','padj']\n",
    "        res=res[['source','target','category','correlation','pvalue','padj']]\n",
    "        res.to_csv('%s/%d_edges.txt' % (self.res_path,self.cat),sep='\\t',index=False)\n",
    "        print('Done!!')\n",
    "        return res\n",
    "    \n",
    "    def __net_analysis_combi(self):\n",
    "        print('Loading The Network...')\n",
    "        temp=self.network_ori\n",
    "        g= ig.Graph.TupleList(zip(temp['source'],temp['target'],temp['correlation']),weights=True)\n",
    "        G_pos = g.subgraph_edges(g.es.select(weight_gt = 0), delete_vertices=False)\n",
    "        G_neg = g.subgraph_edges(g.es.select(weight_lt = 0), delete_vertices=False)\n",
    "        G_neg.es['weight'] = [-w for w in G_neg.es['weight']]\n",
    "        part_pos = leidenalg.ModularityVertexPartition(G_pos, weights='weight')\n",
    "        part_neg = leidenalg.ModularityVertexPartition(G_neg, weights='weight');\n",
    "        optimiser = leidenalg.Optimiser()\n",
    "        diff = optimiser.optimise_partition_multiplex([part_pos, part_neg],layer_weights=[1,-1], n_iterations=-1)\n",
    "        self.clustering_combi=pd.DataFrame(pd.Series(part_pos.membership+part_neg.membership,index=G_pos.vs['name']+G_neg.vs['name'])).reset_index().drop_duplicates().set_index('index')[0]\n",
    "        print('Cluster Analysis...')\n",
    "        self.modularity_combi=diff\n",
    "        open('%s/%d_modularity.txt' % (self.res_path,self.cat),'w').write(str(diff))\n",
    "        self.nodes['cluster'] = self.clustering_combi.reindex(self.nodes.index).tolist()\n",
    "        self.nodes.to_csv('%s/%d_nodes.txt' % (self.res_path,self.cat),sep='\\t')\n",
    "    \n",
    "    def save_network(self):\n",
    "        pickle_out = open('%s/%d_network_object.pkl' % (self.res_path,self.cat),\"wb\")\n",
    "        pickle.dump(self, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "meta=pd.read_csv('../Data/GTEX/metadata_final.txt',sep='\\t',index_col=0)\n",
    "pc=pd.read_csv('../Data/GTEX/protein_coding.txt',sep='\\t',index_col=0)\n",
    "cat=pd.read_csv('../Data/GTEX/category.txt',sep='\\t',index_col=0)\n",
    "\n",
    "i = int(sys.argv[1])\n",
    "\n",
    "temp=['Name']+list(meta[meta['SMTSD'] == cat.loc[i]['name_category']].index)\n",
    "tpm=pd.read_csv('../Data/GTEX/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz', sep='\\t',skiprows=2,index_col=0,usecols=temp).reindex(set(pc.index)).dropna(how='all')\n",
    "tpm=tpm[tpm.mean(1)>1]\n",
    "nodes=pc[['Gene','ensembl']].reindex(tpm.index)\n",
    "nodes.columns=['symbol','info1']\n",
    "mean=tpm.mean(1)\n",
    "sd=tpm.std(1)\n",
    "mins=tpm.min(1)\n",
    "maxs=tpm.max(1)\n",
    "ran=['%.1f - %.1f' % (mins.loc[k],maxs.loc[k]) for k in mins.index]\n",
    "mean=['%.1f (+/- %.1f)' % (mean.loc[k],sd.loc[k]) for k in mins.index]\n",
    "nodes['info2'] = mean\n",
    "nodes['info3'] =ran\n",
    "nodes['location'] = 'GENE'\n",
    "nodes['category'] = i\n",
    "print('StartingNet')\n",
    "k=Network_Analysis(raw_data=tpm,nodes=nodes,respath='../Results/GTEx/',cat=i)\n",
    "# print('SavingNet')\n",
    "# k.save_network()\n",
    "print('Done %d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(i+1) % 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=0\n",
    "for i in cat.index:\n",
    "    print('python GTEX.py %d &' % i)\n",
    "    if (i+1) % 3 == 0:\n",
    "        print('wait')\n",
    "print('wait') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=pd.read_csv('../Data/GTEX/category.txt',sep='\\t',index_col=0)\n",
    "x=[]\n",
    "for i in cat.index:\n",
    "    temp=float(open('../Results/GTEx/modularity/%s_modularity.txt' % i, 'r').read())\n",
    "    x.append(temp)\n",
    "cat['modularity']=x\n",
    "cat.to_csv('../Results/GTEx/category.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8211475790129228"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
